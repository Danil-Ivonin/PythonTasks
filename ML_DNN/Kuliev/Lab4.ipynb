{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GrMuXus5bcZA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Надя\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "from tqdm.contrib import itertools\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3LTrKvwbbcZB",
        "outputId": "f5bbe8d5-2375-4950-ab01-9909abcb1a0d"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 3] Системе не удается найти указанный путь: 'C:/Users/das-s/Downloads/Faces/train'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m      6\u001b[0m                                 transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)),\n\u001b[0;32m      7\u001b[0m                                 transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m), (\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m))])\n\u001b[0;32m      9\u001b[0m train_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/das-s/Downloads/Faces/train\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_ds, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m test_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/das-s/Downloads/Faces/test\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\Надя\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    303\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m ):\n\u001b[1;32m--> 309\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
            "File \u001b[1;32mc:\\Users\\Надя\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    136\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    142\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 144\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
            "File \u001b[1;32mc:\\Users\\Надя\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m    192\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Надя\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:40\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Системе не удается найти указанный путь: 'C:/Users/das-s/Downloads/Faces/train'"
          ]
        }
      ],
      "source": [
        "# Создание и нормализация обучающей, тестовой и выборки валидации\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Resize((128, 128)),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_path = \"C:/Users/das-s/Downloads/Faces/train\"\n",
        "train_ds = datasets.ImageFolder(root=train_path, transform=transform)\n",
        "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_path = \"C:/Users/das-s/Downloads/Faces/test\"\n",
        "test_ds = datasets.ImageFolder(root=test_path, transform=transform)\n",
        "test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "images = []\n",
        "for i in range(4):\n",
        "    images.append(train_features[i])\n",
        "imshow(torchvision.utils.make_grid(images)) # show images\n",
        "print(' '.join(f'{train_ds.classes[train_labels[j]]}\\t' for j in range(4))) # print labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Функция формирования набора данных (картинки и метки)\n",
        "def extract_dataset_images(dataloader):\n",
        "  labels = []\n",
        "  images = []\n",
        "  for batch, batch_labels in tqdm(dataloader):\n",
        "    images.append(batch.detach().numpy().reshape((batch.shape[0], -1))) # Делаем картинки в виде векторов\n",
        "    labels.append(batch_labels.detach().numpy())\n",
        "  return np.concatenate(images), np.concatenate(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, y_train = extract_dataset_images(train_dataloader)\n",
        "x_test, y_test = extract_dataset_images(test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_and_test_KNN(x_train, y_train, x_test, y_test, n_neighbors, metric, weights):\n",
        "  # Обучение KNN на картинках\n",
        "  knn_classifier = KNeighborsClassifier(n_neighbors=n_neighbors, metric = metric, weights = weights)\n",
        "  knn_classifier.fit(x_train, y_train)\n",
        "\n",
        "  # Тестирование\n",
        "  # Классификация тестовых изображений с использованием KNN\n",
        "  y_pred = knn_classifier.predict(x_test)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inverse_squared_distance(dist):\n",
        "    arr = []\n",
        "    for d in dist:\n",
        "        arr.append(1 / (d**2))\n",
        "    return arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics_array = [\"minkowski\", \"euclidean\", \"cosine\"]\n",
        "weights_array = [\"uniform\", \"distance\", inverse_squared_distance]\n",
        "n_neighbors = [3, 5, 10, 20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#KNN accuracy\n",
        "parameters = 0, \"\", \"\"\n",
        "accuracy = 0\n",
        "\n",
        "for metric, weights, n in itertools.product(metrics_array, weights_array, n_neighbors):\n",
        "    temp_accuracy = train_and_test_KNN(x_train, y_train, x_test, y_test, n, metric, weights)\n",
        "    if accuracy < temp_accuracy:\n",
        "        parameters = n, metric, weights\n",
        "        accuracy = temp_accuracy\n",
        "\n",
        "print(\"Best KNN accuracy:\")\n",
        "print(f\"n_neighbors = {parameters[0]} \\nmetric = {parameters[1]} \\nweights = {parameters[2]} \\naccuracy = {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PCA+KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_and_test_PCA_KNN(x_train, y_train, x_test, y_test, n_components, knn_classifier):\n",
        "  pca = PCA(n_components=n_components)\n",
        "  x_train_pca = pca.fit_transform(x_train)\n",
        "  knn_classifier.fit(x_train_pca, y_train)\n",
        "\n",
        "  # Тестирование\n",
        "  # Применение созданного ранее PCA для тестовых данных\n",
        "  x_test_pca = pca.transform(x_test)\n",
        "  # Классификация тестовых изображений с использованием KNN\n",
        "  y_pred = knn_classifier.predict(x_test_pca)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_components = [10, 50, 100, 200, 400]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#KNN + PCA accuracy\n",
        "parameters = 0, \"\", \"\", 0\n",
        "accuracy = 0\n",
        "\n",
        "for metric, weights, n_neigh, n_comp in itertools.product(metrics_array, weights_array, n_neighbors, n_components):\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=n_neigh, metric = metric, weights = weights)\n",
        "    temp_accuracy = train_and_test_PCA_KNN(x_train, y_train, x_test, y_test, n_comp, knn_classifier)\n",
        "    if accuracy < temp_accuracy:\n",
        "        parameters = n_neigh, metric, weights, n_comp\n",
        "        accuracy = temp_accuracy\n",
        "\n",
        "print(\"Best KNN accuracy:\")\n",
        "print(f\"n_neighbors = {parameters[0]} \\nmetric = {parameters[1]} \\nweights = {parameters[2]} \\nn_components = {parameters[3]} \\naccuracy = {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CNN+PCA+KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.models import convnext_base\n",
        "model = convnext_base(pretrained=True)\n",
        "model.classifier = nn.Flatten(start_dim= 1)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_features(dataset, model):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for batch_images, batch_labels in tqdm(dataset):\n",
        "        batch_features = model(batch_images.to(device))\n",
        "        labels.append(batch_labels.detach().numpy())\n",
        "        features.append(batch_features.cpu().detach().numpy())\n",
        "    return np.concatenate(features), np.concatenate(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_features, y_train_labels = extract_features(train_dataloader, model)\n",
        "x_test_features, y_test_labels = extract_features(test_dataloader, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#KNN + PCA + CNN accuracy\n",
        "parameters = 0, \"\", \"\", 0\n",
        "accuracy = 0\n",
        "\n",
        "for metric, weights, n_neigh, n_comp in itertools.product(metrics_array, weights_array, n_neighbors, n_components):\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=n_neigh, metric = metric, weights = weights)\n",
        "    temp_accuracy = train_and_test_PCA_KNN(x_train_features, y_train_labels, x_test_features, y_test_labels, n_comp, knn_classifier)\n",
        "    if accuracy < temp_accuracy:\n",
        "        parameters = n_neigh, metric, weights, n_comp\n",
        "        accuracy = temp_accuracy\n",
        "\n",
        "print(\"Best KNN accuracy:\")\n",
        "print(f\"n_neighbors = {parameters[0]} \\nmetric = {parameters[1]} \\nweights = {parameters[2]} \\nn_components = {parameters[3]} \\naccuracy = {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "knn_classifier = KNeighborsClassifier(n_neighbors=parameters[0], metric=parameters[1], weights=parameters[2])\n",
        "pca = PCA(n_components=parameters[3])\n",
        "\n",
        "x_train_pca = pca.fit_transform(x_train_features)\n",
        "knn_classifier.fit(x_train_pca, y_train_labels)\n",
        "\n",
        "x_test_pca = pca.transform(x_test_features)\n",
        "y_pred = knn_classifier.predict(x_test_pca)\n",
        "\n",
        "print(classification_report(y_test_labels, y_pred, target_names=test_ds.classes))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
